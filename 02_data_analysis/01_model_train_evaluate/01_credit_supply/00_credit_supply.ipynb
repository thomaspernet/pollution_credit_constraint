{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Estimate SO2 emission as a function of  period and others variables\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "- Effect of credit supply\n",
    "\n",
    "## Variables\n",
    "### Target\n",
    "\n",
    "SO2 emission\n",
    "\n",
    "### Features\n",
    "\n",
    "- credit_supply\n",
    "- credit_supply_long_term\n",
    "- credit_supply_short_ term\n",
    "- share_ big bank_loan\n",
    "- share_big_loan\n",
    "\n",
    "## Complementary information\n",
    "\n",
    "Title: Add credit supply\n",
    "Use the new variables such as credit supply in the model to interact with FYP and period\n",
    "Add tfp?\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 171_Pollution_and_Credit_Constraint\n",
    "- Epic: Models\n",
    "- US: Credit supply\n",
    "- Task tag: #data-analysis, #credit-supply\n",
    "- Analytics reports: \n",
    "\n",
    "# Input Cloud Storage\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "- https://github.com/thomaspernet/pollution_credit_constraint/blob/master/01_data_preprocessing/02_transform_tables/00_credit_constraint_industry.md\n",
    "\n",
    "**Github**\n",
    "\n",
    "- fin_dep_pollution_baseline_industry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, json\n",
    "import sys\n",
    "import re\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-2'\n",
    "bucket = 'datalake-london'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "change_target <- function(table){\n",
    "    ## Regime\n",
    "    check_target <- grep(\"periodTRUE:tso2_mandate_c:credit_constraint\", rownames(table$coef))\n",
    "    \n",
    "    if (length(check_target) !=0) {\n",
    "    ## SOE\n",
    "    rownames(table$coefficients)[check_target] <- 'credit_constraint:periodTRUE:tso2_mandate_c'\n",
    "    rownames(table$beta)[check_target] <- 'credit_constraint:periodTRUE:tso2_mandate_c'\n",
    "    } \n",
    "    return (table)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'environment'\n",
    "table = 'fin_dep_pollution_baseline_industry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = True\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT *,\n",
    "    DENSE_RANK() OVER (\n",
    "    ORDER BY \n",
    "      year\n",
    "  ) AS trend,\n",
    "  DENSE_RANK() OVER (\n",
    "    ORDER BY \n",
    "      province_en, year\n",
    "  ) as fe_p_t,\n",
    "  DENSE_RANK() OVER (\n",
    "    ORDER BY \n",
    "      province_en, ind2\n",
    "  ) as fe_p_i\n",
    "  \n",
    "    FROM {}.{}\n",
    "    WHERE so2_intensity > 0\n",
    "    \"\"\".format(db, table)\n",
    "    try:\n",
    "        df = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "              #.assign(\n",
    "              #    trend = lambda x: pd.factorize(x[\"year\"].astype('str')\n",
    "              #                         )[0] + 1\n",
    "              #)\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "    df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Pollution abatement equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH aggregate_pol AS (\n",
    "  SELECT \n",
    "    year, \n",
    "    geocode4_corr, \n",
    "    ind2, \n",
    "    SUM(tlssnl) as tlssnl,\n",
    "    SUM(tdwastegas_equip) as tdwastegas_equip,\n",
    "    SUM(tdso2_equip) as tdso2_equip,\n",
    "    SUM(tfqzlssnl) as tfqzlssnl,\n",
    "    SUM(ttlssnl) as ttlssnl\n",
    "  FROM \n",
    "    (\n",
    "      SELECT \n",
    "        year, \n",
    "        citycode, \n",
    "        geocode4_corr, \n",
    "        --cityen,\n",
    "        --china_city_sector_pollution.cityen,\n",
    "        -- indus_code,\n",
    "        ind2, \n",
    "        tso2, \n",
    "        tlssnl,\n",
    "        tdwastegas_equip,\n",
    "        tdso2_equip,\n",
    "        tfqzlssnl,\n",
    "        ttlssnl,\n",
    "        firmdum,\n",
    "        tfirm\n",
    "        -- lower_location, \n",
    "        --larger_location, \n",
    "        --coastal \n",
    "      FROM \n",
    "        environment.china_city_sector_pollution \n",
    "        INNER JOIN (\n",
    "          SELECT \n",
    "            extra_code, \n",
    "            geocode4_corr--,\n",
    "            --cityen\n",
    "          FROM \n",
    "            chinese_lookup.china_city_code_normalised \n",
    "          GROUP BY \n",
    "            extra_code, \n",
    "            geocode4_corr--,\n",
    "            --cityen\n",
    "        ) as no_dup_citycode ON china_city_sector_pollution.citycode = no_dup_citycode.extra_code\n",
    "    ) \n",
    "  GROUP BY \n",
    "    year, \n",
    "    geocode4_corr, \n",
    "    ind2\n",
    ") \n",
    "SELECT *\n",
    "FROM aggregate_pol\n",
    "\"\"\"\n",
    "df_pol = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Macro variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT no_dup_citycode.geocode4_corr,  year, \n",
    "gdp,\n",
    "population,\n",
    "gdp/population as gdp_cap,\n",
    "employment as employment_macro,\n",
    "fixedasset as fixedasset_macro\n",
    "FROM china.province_macro_data\n",
    "INNER JOIN (\n",
    "          SELECT \n",
    "            extra_code, \n",
    "            geocode4_corr\n",
    "          FROM \n",
    "            chinese_lookup.china_city_code_normalised \n",
    "          GROUP BY \n",
    "            extra_code, \n",
    "            geocode4_corr\n",
    "        ) as no_dup_citycode ON province_macro_data.geocode4_corr = no_dup_citycode.extra_code\n",
    "\"\"\"\n",
    "df_macro = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Bank deregulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def get_company_registration_type(x):\n",
    "    regex = r'有限公司|信用合作联社|有限责任公司|旧市支行|族自治州分行|县支行|市支行|村支行|市分行|农村合作银行|自治区分行|支行|合作社联合社'\\\n",
    "'|分行|资金互助社|信用社联合社|股份公司|住宅金融事业部|国家开发银行|总行营业部|合作金融结算服务中心|信用合作社|信托投资公司'\n",
    "    matches = re.findall(regex,x)\n",
    "    if len(matches) > 0:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return np.nan \n",
    "def get_type(x):\n",
    "    if re.search(r\"中国工商银行|中国建设银行|中国银行|中国农业银行|交通银行|中国邮政储蓄银行\", str(x)):\n",
    "        return (re.search(r\"中国工商银行|中国建设银行|中国银行|中国农业银行|交通银行|中国邮政储蓄银行\", \n",
    "                          str(x)).group(), \"SOB\")\n",
    "    elif re.search(r\"中国农业发展银行|国家开发银行|中国进出口银行\", str(x)):\n",
    "        return (re.search(r\"中国农业发展银行|国家开发银行|中国进出口银行\", str(x)).group(),\n",
    "                \"policy bank\")\n",
    "    elif re.search(r\"股份制商业银行\", str(x)):\n",
    "        return (re.search(r\"股份制商业银行|银行股份\", str(x)).group(), \"joint-stock commercial bank\")\n",
    "    elif re.search(r\"城市商业银行\", str(x)):\n",
    "        return (re.search(r\"城市商业银行\", str(x)).group(), \"city commercial bank\")\n",
    "    elif re.search(r\"农村商业银行\", str(x)):\n",
    "        return (re.search(r\"农村商业银行\", str(x)).group(), \"rural commercial bank\")\n",
    "    elif re.search(r\"外资银行\", str(x)):\n",
    "        return (re.search(r\"外资银行\", str(x)).group(), \"foreign bank\")\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM china.branches_raw_csv\n",
    "\"\"\"\n",
    "df_bank = (\n",
    "    s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=\"bank\",  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype = {'id':'str','geocode4_corr':'str', 'lostReason':'str',\n",
    "                       'location':'str', 'city_temp':'str', 'points':'str'}\n",
    "    )\n",
    "    .assign(\n",
    "        setdate=lambda x: pd.to_datetime(x[\"setdate\"].astype(\"Int64\").astype(str), errors ='coerce'),\n",
    "        printdate=lambda x: pd.to_datetime(x[\"printdate\"].astype(\"Int64\").astype(str), errors ='coerce'),\n",
    "        year_setdate=lambda x: x[\"setdate\"].dt.year.astype(\"Int64\").astype(str),\n",
    "        bank_temp=lambda x: x.apply(\n",
    "            lambda x: get_company_registration_type(x[\"fullname\"]), axis=1\n",
    "        ),\n",
    "        geocode4_corr = lambda x: x['geocode4_corr'].astype(\"Int64\").astype(str)\n",
    "    )\n",
    "     .assign(\n",
    "         registration_type=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"bank_temp\"]) else x[\"bank_temp\"], axis=1\n",
    "        ),\n",
    "        bank_full_name=lambda x: x.apply(\n",
    "            lambda x: x[\"fullname\"]\n",
    "            if pd.isna(x[\"bank_temp\"])\n",
    "            else x[\"fullname\"].split(x[\"registration_type\"][0])[0],\n",
    "            axis=1,\n",
    "        ),\n",
    "        list_bank_type=lambda x: x.apply(lambda x: get_type(x[\"bank_full_name\"]), axis=1),\n",
    "        bank_type=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"list_bank_type\"]) else x[\"list_bank_type\"][0], axis=1\n",
    "        ),\n",
    "        bank_type_adj=lambda x: x.apply(\n",
    "            lambda x: np.nan if pd.isna(x[\"list_bank_type\"]) else x[\"list_bank_type\"][1], axis=1\n",
    "        )\n",
    "    )\n",
    "    .drop(columns=[\"bank_temp\"])\n",
    ")\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM china.china_bank_information\n",
    "\"\"\"\n",
    "df_bank_info = (\n",
    "    s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "        filename=\"bank\",  # Add filename to print dataframe\n",
    "        destination_key=\"SQL_OUTPUT_ATHENA/CSV\",  # Use it temporarily\n",
    "        dtype=dtypes,\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"shortbnm\"])\n",
    "    .replace(\n",
    "        {\n",
    "            \"bnature\": {\n",
    "                1: \"政策性银行\",\n",
    "                2: \"国有控股大型商业银行\",\n",
    "                3: \"股份制商业银行\",\n",
    "                4: \"城市商业银行\",\n",
    "                5: \"农村商业银行\",\n",
    "                6: \"外资银行\",\n",
    "                7: \"其他\",\n",
    "                8: \"农合行\",\n",
    "                9: \"农信社\",\n",
    "                10: \"三类新型农村金融机构\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_bank_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank.loc[lambda x: ~x['geocode4_corr'].isin([\"<NA>\"])].shape[0]/df_bank.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank['registration_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank['bank_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank['bank_type_adj'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_bank\n",
    "    .loc[lambda x: x['setdate'] < \"2022\"]\n",
    "    .set_index(['setdate'])\n",
    "    .groupby([pd.Grouper(freq='Y')])\n",
    "    .agg({\"id\":\"nunique\"})\n",
    "    .assign(cumsum = lambda x: x['id'].cumsum())\n",
    "    .drop(columns = ['id'])\n",
    "    .plot\n",
    "    .line(title = 'total branches over time',figsize=(8,8))\n",
    "    .legend(loc='center left',bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_bank\n",
    "    .loc[lambda x: x['setdate'] < \"2022\"]\n",
    "    .set_index(['setdate'])\n",
    "    .groupby([pd.Grouper(freq='Y')])\n",
    "    .agg({\"id\":\"nunique\"})\n",
    "    #.assign(cumsum = lambda x: x['id'].cumsum())\n",
    "    #.drop(columns = ['id'])\n",
    "    .plot\n",
    "    .line(title = 'Accumulation branches over time',figsize=(8,8))\n",
    "    .legend(loc='center left',bbox_to_anchor=(1.0, 0.5))   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "list of banks in China\n",
    "\n",
    "- Policy banks: China has three policy banks. Among them, China Development Bank was incorporated in December 2008 and officially defined by the State Council as a development finance institution in March 2015\n",
    "    - 中国农业发展银行\n",
    "    - 国家开发银行\n",
    "    - 中国进出口银行\n",
    "- State-owned Commercial Banks: China has six state-owned commercial banks. These banks are ranked by their Tier 1 capital amount as of 2018. \n",
    "    - 中国工商银行\n",
    "    - 中国建设银行\n",
    "    - 中国银行\n",
    "    - 中国农业银行\n",
    "    - 交通银行\n",
    "    - 中国邮政储蓄银行\n",
    "- Commercial Banks: China has 12 national commercial banks. These banks are ordered by their Tier 1 capital amount as of 2018\n",
    "    - 招商银行\n",
    "    - 上海浦东发展银行\n",
    "    - 兴业银行\n",
    "    - 中信银行\n",
    "    - 中国民生银行\n",
    "    - 中国光大银行\n",
    "    - 平安银行\n",
    "    - 华夏银行\n",
    "    - 广发银行\n",
    "    - 浙商银行\n",
    "    - 渤海银行\n",
    "    - 恒丰银行\n",
    "    \n",
    "Source: https://en.wikipedia.org/wiki/List_of_banks_in_China. More info in CSMAR data (where we got the data)df_bank_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from polyfuzz import PolyFuzz\n",
    "from polyfuzz.models import RapidFuzz\n",
    "from polyfuzz.models import Embeddings\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\",rc={'figure.figsize':(15,10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We already know the status of 75% of our dataset. The remaining banks are mostly city banks, so we well use fuzzy string matching to find them from the CSMAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank['bank_type_adj'].dropna().shape[0]/df_bank.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks = (\n",
    "    [ i.replace('（中国）','').strip() for i in \n",
    "     df_bank.loc[lambda x: x['bank_type_adj'].isin([np.nan])]['bank_full_name'].dropna().drop_duplicates().to_list()\n",
    "     if len(i) > 1]\n",
    ")\n",
    "bank_info = df_bank_info['shortbnm'].to_list()\n",
    "#bank_info_pinyin =  [pinyin.get(i, format=\"strip\", delimiter=\" \") for i in bank_info]\n",
    "#model = PolyFuzz(rapidfuzz_matcher).match(banks, bank_info)\n",
    "#model.get_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Let's make sure the city (or at least the location) is in the name; We can use this transformers https://huggingface.co/Davlan/xlm-roberta-base-wikiann-ner?text=%E6%9C%9D%E9%98%B3%E5%B8%82%E5%8F%8C%E5%A1%94%E5%8C%BA%E5%86%9C%E6%9D%91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/xlm-roberta-base-wikiann-ner\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Davlan/xlm-roberta-base-wikiann-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def get_proba_city(x):\n",
    "    ner = pipeline(\"ner\", tokenizer=tokenizer,model=model,aggregation_strategy='simple')\n",
    "    ner_results = ner(x)\n",
    "    if len([i for i in ner_results if i['entity_group'] == 'LOC']) >0:\n",
    "        dic = max(\n",
    "            [i for i in ner_results if i['entity_group'] == 'LOC'],\n",
    "            key=lambda x:x['score']\n",
    "        )\n",
    "        dic['name'] = x\n",
    "        dic['applicable'] = True\n",
    "    else:\n",
    "        dic =  max(ner_results, key=lambda x:x['score'])\n",
    "        dic['name'] = x\n",
    "        dic['applicable'] = False\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "regex_loc = '|'.join(df_bank_info['cityname'].drop_duplicates().to_list()) + \\\n",
    "'|'+'|'.join(df_bank_info['provincename'].drop_duplicates().to_list()) + \\\n",
    "'|'+ '|'.join([i.replace('市',\"\").replace(\"省\",'').replace('自治区',\"\")\n",
    " for i in df_bank_info['provincename'].drop_duplicates().to_list()]) + \\\n",
    "'|'+ '|'.join([i.replace('市',\"\").replace(\"省\",'').replace('自治区',\"\")\n",
    " for i in df_bank_info['cityname'].drop_duplicates().to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "true_loc = [i for i in banks if re.search(regex_loc,i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_branch_to_check = pd.DataFrame([get_proba_city(i) for i in tqdm(banks) if i not in true_loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_branch_to_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_branch_to_check\n",
    "    .groupby(['applicable'])\n",
    "    .agg({'name':'unique'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "we can remove the branches which are not location, which mean we need to find 1774 differents banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks_to_find = sorted(true_loc + df_branch_to_check.loc[lambda x: x['applicable'].isin([True])]['name'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "banks_to_find[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "to_find = False\n",
    "if to_find:\n",
    "    bert = TransformerWordEmbeddings('bert-base-multilingual-cased')\n",
    "    bert_matcher = Embeddings(bert, min_similarity=0)\n",
    "    models = PolyFuzz(bert_matcher).match(banks_to_find, bank_info)\n",
    "    models.get_matches().to_csv('branch_matches.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#bank_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from polyfuzz.models import RapidFuzz\n",
    "rapidfuzz_matcher = RapidFuzz(n_jobs=1)\n",
    "model = PolyFuzz(rapidfuzz_matcher).match(banks_to_find, bank_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    model.get_matches()\n",
    "    .sort_values(by = ['Similarity'])\n",
    "    .loc[lambda x: x[\"Similarity\"] > 0.85]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank_branches = (\n",
    "    pd.read_csv(\n",
    "        \"branch_matches.csv\",\n",
    "        dtype={\n",
    "            \"id\": \"str\",\n",
    "            \"geocode4_corr\": \"str\",\n",
    "            \"lostReason\": \"str\",\n",
    "            \"location\": \"str\",\n",
    "            \"city_temp\": \"str\",\n",
    "            \"points\": \"str\",\n",
    "        },\n",
    "    )\n",
    "    .sort_values(by=[\"Similarity\"])\n",
    "    .loc[lambda x: x[\"Similarity\"] > 0.85]\n",
    "    .merge(\n",
    "        df_bank_info.reindex(columns=[\"bnm_cn\", \"shortbnm\", \"bnature\"]).rename(\n",
    "            columns={\"shortbnm\": \"To\"}\n",
    "        )\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"bnature\": {\n",
    "                \"政策性银行\": \"policy bank\",\n",
    "                \"国有控股大型商业银行\": \"sob\",\n",
    "                \"股份制商业银行\": \"joint-stock commercial bank\",\n",
    "                \"城市商业银行\": \"city commercial bank\",\n",
    "                \"农村商业银行\": \"rural commercial bank\",\n",
    "                \"外资银行\": \"foreign bank\",\n",
    "                \"其他\": \"other\",\n",
    "                \"农合行\": \"other\",\n",
    "                \"农信社\": \"other\",\n",
    "                \"三类新型农村金融机构\": \"other\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .rename(columns={\"bnature\": \"bank_type_adj\"})\n",
    "    .merge(\n",
    "        (\n",
    "            df_bank.drop_duplicates(subset=[\"bank_full_name\"])\n",
    "            .reindex(\n",
    "                columns=[\n",
    "                    \"id\",\n",
    "                    \"setdate\",\n",
    "                    \"year_setdate\",\n",
    "                    \"fullname\",\n",
    "                    \"bank_full_name\",\n",
    "                    \"registration_type\",\n",
    "                    \"city\",\n",
    "                    \"geocode4_corr\",\n",
    "                    \"bank_type\",\n",
    "                    # \"bank_type_adj\",\n",
    "                ]\n",
    "            )\n",
    "            .assign(\n",
    "                bank_full_name_=lambda x: x[\"bank_full_name\"]\n",
    "                .replace(\"（中国）\", \"\")\n",
    "                .str.strip()\n",
    "            )\n",
    "            .rename(columns={\"bank_full_name_\": \"From\"})\n",
    "        )\n",
    "    )\n",
    "    .reindex(\n",
    "        columns=[\n",
    "            \"id\",\n",
    "            \"setdate\",\n",
    "            \"year_setdate\",\n",
    "            \"fullname\",\n",
    "            \"bank_full_name\",\n",
    "            \"registration_type\",\n",
    "            \"city\",\n",
    "            \"geocode4_corr\",\n",
    "            \"bank_type\",\n",
    "            \"bank_type_adj\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "df_bank_branches = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            df_bank.loc[\n",
    "                lambda x: ~x[\"id\"].isin(df_bank_branches[\"id\"].to_list())\n",
    "            ].reindex(\n",
    "                columns=[\n",
    "                    \"id\",\n",
    "                    \"setdate\",\n",
    "                    \"year_setdate\",\n",
    "                    \"fullname\",\n",
    "                    \"bank_full_name\",\n",
    "                    \"registration_type\",\n",
    "                    \"city\",\n",
    "                    \"geocode4_corr\",\n",
    "                    \"bank_type\",\n",
    "                    \"bank_type_adj\",\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "        df_bank_branches,\n",
    "    ]\n",
    ").assign(\n",
    "    bank_type_adj_clean=lambda x: x.groupby([\"bank_full_name\"])[\n",
    "        \"bank_type_adj\"\n",
    "    ].transform(lambda x: x.ffill().bfill())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_bank_branches\n",
    "    .loc[lambda x: x[\"bank_type_adj_clean\"].isin(['city commercial bank'])]\n",
    "    ['bank_full_name']\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .sort_values(by = ['index'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Example of banks without confident bank type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pd.read_csv(\n",
    "        \"branch_matches.csv\",\n",
    "        dtype={\n",
    "            \"id\": \"str\",\n",
    "            \"geocode4_corr\": \"str\",\n",
    "            \"lostReason\": \"str\",\n",
    "            \"location\": \"str\",\n",
    "            \"city_temp\": \"str\",\n",
    "            \"points\": \"str\",\n",
    "        },\n",
    "    )\n",
    "    .sort_values(by=[\"From\"])\n",
    "    .loc[lambda x: x[\"Similarity\"] <= 0.85]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_bank_branches['bank_type_adj_clean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#from matplotlib import font_manager as fm, rcParams\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import requests\n",
    "#filename = Path('simhei.zip')\n",
    "#url = 'http://legionfonts.com/download/simhei'\n",
    "#response = requests.get(url)\n",
    "#filename.write_bytes(response.content)\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#    zip_ref.extractall(os.path.join(rcParams[\"datapath\"], \"fonts/ttf/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "temp= (\n",
    "    df_bank_branches\n",
    "    .loc[lambda x: ~x[\"bank_type_adj_clean\"].isin([\n",
    "        \"SOB\",\n",
    "        \"rural commercial bank\",\n",
    "        'policy bank',\n",
    "        'other',\n",
    "        'joint-stock commercial bank',\n",
    "        'foreign bank'\n",
    "    ])]\n",
    "    #.loc[lambda x: x['setdate'] < \"2013\"]\n",
    "    #\n",
    "    #.set_index(['setdate'])\n",
    "    .loc[lambda x: ~x['geocode4_corr'].isin([\"<NA>\"])]\n",
    "    .dropna(subset = ['bank_type_adj_clean'])\n",
    "    .groupby(['bank_type_adj_clean', 'bank_full_name'])\n",
    "    .agg({\n",
    "        \"year_setdate\":\"min\",\n",
    "    })\n",
    "    .reset_index()\n",
    "    .groupby(['year_setdate','bank_type_adj_clean'])\n",
    "    .agg({'bank_full_name':'count'})\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        year_setdate = lambda x: pd.to_datetime(x['year_setdate']),\n",
    "        bank_name_adjusted = lambda x: x.groupby('bank_type_adj_clean')['bank_full_name'].transform('cumsum')\n",
    "    )\n",
    "    .loc[lambda x: x['year_setdate'] >= \"1995\"]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=temp, x=\"year_setdate\", y=\"bank_name_adjusted\", hue=\"bank_type_adj_clean\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "temp = (\n",
    "    df_bank_branches\n",
    "    .loc[lambda x: ~x[\"bank_type_adj_clean\"].isin([\"SOB\", \"rural commercial bank\",\n",
    "                                                   'policy bank', 'other',\n",
    "                                                   'joint-stock commercial bank','foreign bank'])]\n",
    "    .loc[lambda x: x['setdate'] < \"2013\"]\n",
    "    .loc[lambda x: x['setdate'] >= \"1995\"]\n",
    "    #.loc[lambda x: x['bank_type'].isin(['COMMERCIAL BANKS'])]\n",
    "    .set_index(['setdate'])\n",
    "    .groupby([pd.Grouper(freq='Y'), 'bank_type_adj_clean'])\n",
    "    .agg({\"bank_full_name\":\"count\"})\n",
    "    .assign(bank_name_adjusted = lambda x: x.groupby('bank_type_adj_clean')['bank_full_name'].transform('cumsum'))\n",
    "    .reset_index()\n",
    ")\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=temp, x=\"setdate\", y=\"bank_name_adjusted\", hue=\"bank_type_adj_clean\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Compute Herfhindal index:\n",
    "\n",
    "$$\n",
    "H H I_{c, t}=\\sum_{k=1}^{N}\\left(\\frac{\\text { Number of } \\text { Branches }_{k t}}{\\sum_{k=1}^{N} \\text { Number of } \\text { Branches }_{k t }}\\right)^{2} .\n",
    "$$\n",
    "\n",
    "represents the HHI of the local banking market in city $c$ and\n",
    "is calculated on the basis of the number of bank branches of all banks k locally present for each year (with\n",
    "N the total number of banks in the country).\n",
    "\n",
    "We need to make a panel for each bank because the data only shows when a new branch is added, but in the case where there is no new branch, the bank has still a market share.\n",
    "\n",
    "See example below, the bank \"上海银行股份\" is in business since 2009, and created 2 other branches in 2011. In 2010, the bank was still opearting the branch, so we need to create this new row\n",
    "\n",
    "The bank regulation index:\n",
    "\n",
    "$$\n",
    "\\operatorname{Bank}_{\\mathrm{HHI}_{c, t}}=1-\\mathrm{HHI}_{c, t}\n",
    "$$\n",
    "\n",
    "It ranges from zero to one with zero indicating the most stringent regulation and one indicating the most deregulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "temp = (\n",
    "    df_bank_branches\n",
    "    .loc[lambda x: ~x[\"bank_type_adj_clean\"].isin([#\"SOB\",\n",
    "        \"rural commercial bank\",\n",
    "        'policy bank', 'other',\n",
    "        'joint-stock commercial bank','foreign bank'])]\n",
    "    .loc[lambda x: x['setdate'] < \"2013\"]\n",
    "    .loc[lambda x: ~x['geocode4_corr'].isin([\"<NA>\"])]\n",
    "    .dropna(subset = ['bank_type_adj_clean'])\n",
    "    .groupby(['year_setdate', 'geocode4_corr', 'bank_full_name'])\n",
    "    .agg({'id':'count'})\n",
    "    .sort_values(by = [\"bank_full_name\",\"geocode4_corr\", \"year_setdate\"])\n",
    "    .loc[lambda x: x.index.get_level_values('bank_full_name').isin(['上海银行股份'])]\n",
    "    #.loc[lambda x: x.index.get_level_values('geocode4_corr').isin(['1101'])]\n",
    "    .reset_index()\n",
    ")\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_bank_branches.loc[lambda x: ~x[\"geocode4_corr\"].isin([\"<NA>\"])]\n",
    "    .dropna(subset=[\"bank_type_adj_clean\", \"bank_type_adj\"])\n",
    "    .groupby([\"year_setdate\", \"geocode4_corr\", \"bank_full_name\"])\n",
    "    .agg({\"id\": \"count\"})\n",
    "    .sort_values(by=[\"bank_full_name\", \"geocode4_corr\", \"year_setdate\"])\n",
    "    .reset_index()\n",
    "    .pivot_table(\n",
    "        values=\"id\",\n",
    "        index=[\"bank_full_name\", \"geocode4_corr\"],\n",
    "        columns=\"year_setdate\",\n",
    "        aggfunc=np.sum,\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .assign(\n",
    "        totalBranchBank=lambda x: x.groupby([\"bank_full_name\", \"geocode4_corr\"])[\n",
    "            \"count\"\n",
    "        ].transform(\"cumsum\"),\n",
    "        totalBranchCity=lambda x: x.groupby([\"geocode4_corr\", \"year_setdate\"])[\n",
    "            \"totalBranchBank\"\n",
    "        ].transform(\"sum\"),\n",
    "        score=lambda x: (x[\"totalBranchBank\"] / x[\"totalBranchCity\"]) ** 2,\n",
    "    )\n",
    "    .groupby([\"year_setdate\", \"geocode4_corr\"])\n",
    "    .agg({\"score\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .dropna(subset=[\"score\"])\n",
    "    .assign(deregulation_ct=lambda x: 1 - x[\"score\"])\n",
    "    .loc[lambda x: x['year_setdate'] > \"1995\"]\n",
    "    .drop(columns=[\"score\"])\n",
    "    .groupby('year_setdate')\n",
    "    .agg({'deregulation_ct':'mean'})\n",
    "    .plot.line(title=\"deregulation\", figsize=(15, 10))\n",
    "    .legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Concentration ratio\n",
    "\n",
    "$$\n",
    "\\mathrm{CR}_{\\text {bigfour }_{c, t}}=\\left(\\operatorname{Branch}_{c, t}^{\\mathrm{BOC}}+\\operatorname{Branch}_{c, t}^{\\mathrm{ICBC}}+\\operatorname{Branch}_{c, t}^{\\mathrm{CCB}}+\\operatorname{Branch}_{c, t}^{\\mathrm{ABC}}\\right) / \\text { TotalBranch }_{c, t}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "Bank of China (BOC), Agricultural Bank of China (ABC), China Construction Bank (CCB) and Industrial and Commercial Bank of China (ICBC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def big_four(x):\n",
    "    if x == \"中国农业银行股份\":\n",
    "        return \"中国农业银行股份\"\n",
    "    elif x == \"中国工商银行股份\":\n",
    "        return \"中国工商银行股份\"\n",
    "    elif x == \"中国建设银行股份\":\n",
    "        return \"中国建设银行股份\"\n",
    "    elif x == \"中国银行股份\":\n",
    "        return \"中国银行股份\"\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_bank_branches.assign(\n",
    "        sob=lambda x: x.apply(lambda x: big_four(x[\"bank_full_name\"]), axis=1)\n",
    "    )\n",
    "    .loc[lambda x: ~x[\"geocode4_corr\"].isin([\"<NA>\"])]\n",
    "    .dropna(subset=[\"bank_type_adj_clean\", \"bank_type_adj\"])\n",
    "    .groupby([\"year_setdate\", \"geocode4_corr\", \"sob\"])\n",
    "    .agg({\"id\": \"count\"})\n",
    "    .sort_values(by=[\"sob\", \"geocode4_corr\", \"year_setdate\"])\n",
    "    .reset_index()\n",
    "    .pivot_table(\n",
    "        values=\"id\",\n",
    "        index=[\"sob\", \"geocode4_corr\"],\n",
    "        columns=\"year_setdate\",\n",
    "        aggfunc=np.sum,\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"count\"})\n",
    "    .assign(\n",
    "        totalBranchBank=lambda x: x.groupby([\"sob\", \"geocode4_corr\"])[\n",
    "            \"count\"\n",
    "        ].transform(\"cumsum\"),\n",
    "        totalBranchCity=lambda x: x.groupby([\"geocode4_corr\", \"year_setdate\"])[\n",
    "            \"totalBranchBank\"\n",
    "        ].transform(\"sum\"),\n",
    "        #    score = lambda x: (x['totalBranchBank']/x['totalBranchCity'])**2\n",
    "    )\n",
    "    .loc[lambda x: x[\"sob\"] != \"other\"]\n",
    "    .set_index([\"sob\", \"geocode4_corr\", \"year_setdate\", \"totalBranchCity\"])\n",
    "    .drop(columns=[\"count\"])\n",
    "    .unstack(0)\n",
    "    .assign(total_sob=lambda x: x.sum(axis=1))\n",
    "    .reset_index([\"totalBranchCity\"])\n",
    "    .assign(\n",
    "        concentration_sob=lambda x: x[(\"total_sob\", \"\")] / x[(\"totalBranchCity\", \"\")]\n",
    "    )\n",
    "    .reindex(columns=[(\"total_sob\", \"\"), (\"concentration_sob\", \"\")])\n",
    "    .droplevel(axis=1, level=1)\n",
    "    .reset_index()\n",
    "    .dropna(subset=[\"concentration_sob\"])\n",
    "    .assign(concentration_sob_ct=lambda x: 1 - x[\"concentration_sob\"])\n",
    "    .loc[lambda x: x['year_setdate'] > \"1995\"]\n",
    "    .groupby(\"year_setdate\")\n",
    "    .agg({\"concentration_sob_ct\": \"mean\"})\n",
    "    # .drop(columns = ['concentration_sob'])\n",
    "    .plot.line(title=\"concentration SOB\", figsize=(15, 10))\n",
    "    .legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Add the data to the pollution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_deregulation = (\n",
    "    (\n",
    "        df_bank_branches.loc[lambda x: ~x[\"geocode4_corr\"].isin([\"<NA>\"])]\n",
    "        .dropna(subset=[\"bank_type_adj_clean\", \"bank_type_adj\"])\n",
    "        .pivot_table(\n",
    "            values=\"id\",\n",
    "            index=[\"bank_type_adj_clean\", \"geocode4_corr\"],\n",
    "            columns=\"year_setdate\",\n",
    "            aggfunc=len,\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"count\"})\n",
    "        .assign(\n",
    "            count=lambda x: x.groupby([\"bank_type_adj_clean\", \"geocode4_corr\"])[\n",
    "                \"count\"\n",
    "            ].transform(\"cumsum\")\n",
    "        )\n",
    "        .set_index([\"bank_type_adj_clean\", \"geocode4_corr\", \"year_setdate\"])\n",
    "        .unstack(0)\n",
    "        .fillna(0)\n",
    "        .droplevel(axis=1, level=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            df_bank_branches\n",
    "            .loc[lambda x: ~x[\"geocode4_corr\"].isin([\"<NA>\"])]\n",
    "            .loc[lambda x: ~x[\"bank_type_adj_clean\"].isin([\n",
    "                \"SOB\", \n",
    "                #\"rural commercial bank\",\n",
    "                #'policy bank',\n",
    "                #'other',\n",
    "                #'joint-stock commercial bank',\n",
    "                #'foreign bank'\n",
    "            ])]\n",
    "            .dropna(subset=[\"bank_type_adj_clean\", \"bank_type_adj\"])\n",
    "            .groupby([\"year_setdate\", \"geocode4_corr\", \"bank_full_name\"])\n",
    "            .agg({\"id\": \"count\"})\n",
    "            .sort_values(by=[\"bank_full_name\", \"geocode4_corr\", \"year_setdate\"])\n",
    "            .reset_index()\n",
    "            .pivot_table(\n",
    "                values=\"id\",\n",
    "                index=[\"bank_full_name\", \"geocode4_corr\"],\n",
    "                columns=\"year_setdate\",\n",
    "                aggfunc=np.sum,\n",
    "                fill_value=0,\n",
    "            )\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"count\"})\n",
    "            .assign(\n",
    "                totalBranchBank=lambda x: x.groupby(\n",
    "                    [\"bank_full_name\", \"geocode4_corr\"]\n",
    "                )[\"count\"].transform(\"cumsum\"),\n",
    "                totalBranchCity=lambda x: x.groupby([\"geocode4_corr\", \"year_setdate\"])[\n",
    "                    \"totalBranchBank\"\n",
    "                ].transform(\"sum\"),\n",
    "                deregulation=lambda x: (x[\"totalBranchBank\"] / x[\"totalBranchCity\"]) ** 2,\n",
    "            )\n",
    "            .groupby([\"year_setdate\", \"geocode4_corr\"])\n",
    "            .agg({\"deregulation\": \"sum\"})\n",
    "            .reset_index()\n",
    "            .dropna(subset=[\"deregulation\"])\n",
    "            .assign(deregulation_ct=lambda x: 1 - x[\"deregulation\"])\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"year_setdate\", \"geocode4_corr\"],\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            df_bank_branches.assign(\n",
    "                sob=lambda x: x.apply(lambda x: big_four(x[\"bank_full_name\"]), axis=1)\n",
    "            )\n",
    "            .loc[lambda x: ~x[\"geocode4_corr\"].isin([\"<NA>\"])]\n",
    "            .dropna(subset=[\"bank_type_adj_clean\", \"bank_type_adj\"])\n",
    "            .groupby([\"year_setdate\", \"geocode4_corr\", \"sob\"])\n",
    "            .agg({\"id\": \"count\"})\n",
    "            .sort_values(by=[\"sob\", \"geocode4_corr\", \"year_setdate\"])\n",
    "            .reset_index()\n",
    "            .pivot_table(\n",
    "                values=\"id\",\n",
    "                index=[\"sob\", \"geocode4_corr\"],\n",
    "                columns=\"year_setdate\",\n",
    "                aggfunc=np.sum,\n",
    "                fill_value=0,\n",
    "            )\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"count\"})\n",
    "            .assign(\n",
    "                totalBranchBank=lambda x: x.groupby([\"sob\", \"geocode4_corr\"])[\n",
    "                    \"count\"\n",
    "                ].transform(\"cumsum\"),\n",
    "                totalBranchCity=lambda x: x.groupby([\"geocode4_corr\", \"year_setdate\"])[\n",
    "                    \"totalBranchBank\"\n",
    "                ].transform(\"sum\"),\n",
    "                #    score = lambda x: (x['totalBranchBank']/x['totalBranchCity'])**2\n",
    "            )\n",
    "            .loc[lambda x: x[\"sob\"] != \"other\"]\n",
    "            .set_index([\"sob\", \"geocode4_corr\", \"year_setdate\", \"totalBranchCity\"])\n",
    "            .drop(columns=[\"count\"])\n",
    "            .unstack(0)\n",
    "            .assign(total_sob=lambda x: x.sum(axis=1))\n",
    "            .reset_index([\"totalBranchCity\"])\n",
    "            .assign(\n",
    "                concentration_sob=lambda x: x[(\"total_sob\", \"\")]\n",
    "                / x[(\"totalBranchCity\", \"\")]\n",
    "            )\n",
    "            .reindex(columns=[(\"total_sob\", \"\"), (\"concentration_sob\", \"\")])\n",
    "            .droplevel(axis=1, level=1)\n",
    "            .reset_index()\n",
    "            .dropna(subset=[\"concentration_sob\"])\n",
    "            .assign(concentration_sob_ct=lambda x: 1 - x[\"concentration_sob\"])\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"year_setdate\", \"geocode4_corr\"],\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"city commercial bank\": \"city_commercial_bank\",\n",
    "            \"foreign bank\": \"foreign_bank\",\n",
    "            \"joint-stock commercial bank\": \"joint_stock_commercial_bank\",\n",
    "            \"policy bank\": \"policy_bank\",\n",
    "            \"rural commercial bank\": \"rural_commercial_bank\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df_deregulation = (\n",
    "    df_deregulation\n",
    "    .assign(\n",
    "    **{'lag_{}'.format(i): df_deregulation.groupby(['geocode4_corr'])[i].transform('shift') for \n",
    "        i in ['deregulation','deregulation_ct','deregulation','concentration_sob_ct']\n",
    "      }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_deregulation\n",
    "    .loc[lambda x: x['geocode4_corr'].isin(['6110'])]\n",
    "    .loc[lambda x: x['year_setdate'] > \"2000\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "save new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .merge(\n",
    "    df_pol, on = ['year', 'ind2', 'geocode4_corr'], how = 'left'\n",
    "    )\n",
    "    .merge(\n",
    "    df_macro, on = ['year', 'geocode4_corr'], how = 'left'\n",
    "    )\n",
    "    .assign(\n",
    "        tso2_eq_output = lambda x: (x['tdso2_equip'])/(x['output']/1000),\n",
    "        tso2_eq_output_1 = lambda x: (x['tdso2_equip']+1)/(x['output']/1000),\n",
    "        tso2_eq_asset = lambda x: (x['tdso2_equip'])/(x['total_asset']/1000),\n",
    "        tso2_eq_asset_1 = lambda x: (x['tdso2_equip']+1)/(x['total_asset']/1000),\n",
    "        constraint = lambda x: x['credit_constraint'] > -0.44,\n",
    "        constraint_1 = lambda x: x['credit_constraint'] > -0.26,\n",
    "        target = lambda x: np.where(x['tdso2_equip'] > 0, 1,0),\n",
    "        equipment_s02 = lambda x: (x['tdso2_equip']/x['tso2'])*100,\n",
    "        intensity=lambda x: x[\"ttlssnl\"]/ x[\"sales\"],\n",
    "        year = lambda x: x['year'].astype(int),\n",
    "        geocode4_corr = lambda x: x['geocode4_corr'].astype(str),\n",
    "    )\n",
    "    .merge(df_deregulation.rename(columns ={'year_setdate':'year'}).assign(\n",
    "        year = lambda x: x['year'].astype(int),\n",
    "        geocode4_corr = lambda x: x['geocode4_corr'].astype(str),\n",
    "    ), how = 'left', on = ['year', 'geocode4_corr'])\n",
    "    .to_csv(os.path.join(path_local, filename + '.csv'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = True\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "    data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename =  [\n",
    "        {\n",
    "        'old':'periodTRUE',\n",
    "        'new':'\\\\text{period}'\n",
    "        },\n",
    "        {\n",
    "        'old':'period',\n",
    "        'new':'\\\\text{period}'\n",
    "        },\n",
    "        \n",
    "        ### depd\n",
    "        ###mandate\n",
    "        {\n",
    "        'old':'tso2\\_mandate\\_c',\n",
    "        'new':'\\\\text{S02 mandate}_c'\n",
    "        },\n",
    "        {\n",
    "        'old':'target\\_reduction\\_so2\\_p',\n",
    "        'new':'\\\\text{S02 mandate}_p'\n",
    "        },\n",
    "        {\n",
    "        'old':'target\\_reduction\\_co2\\_p',\n",
    "        'new':'\\\\text{COD mandate}_p'\n",
    "        },\n",
    "        ### financial ratio\n",
    "        {\n",
    "        'old':'total\\_asset',\n",
    "        'new':'\\\\text{total asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'tangible',\n",
    "        'new':'\\\\text{tangible asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'investment\\_tot\\_asset',\n",
    "        'new':'\\\\text{investment to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'rd\\_tot\\_asset',\n",
    "        'new':'\\\\text{rd to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'asset\\_tangibility\\_tot\\_asset',\n",
    "        'new':'\\\\text{asset tangibility}'\n",
    "        },\n",
    "        {\n",
    "        'old':'d\\_avg\\_ij\\_o\\_city\\_mandate',\n",
    "        'new':'\\\\text{relative reduction mandate}_c'\n",
    "        },\n",
    "        ### ind\n",
    "        {\n",
    "        'old':'current\\_ratio',\n",
    "        'new':'\\\\text{current ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_current\\_ratio',\n",
    "        'new':'\\\\text{current ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'quick\\_ratio',\n",
    "        'new':'\\\\text{quick ratio}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_liabilities\\_tot\\_asset',\n",
    "        'new':'\\\\text{liabilities to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'liabilities\\_tot\\_asset',\n",
    "        'new':'\\\\text{liabilities to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'sales\\_tot\\_asset',\n",
    "        'new':'\\\\text{sales to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_sales\\_tot\\_asset',\n",
    "        'new':'\\\\text{sales to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cash\\_tot\\_asset',\n",
    "        'new':'\\\\text{cash to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cashflow\\_tot\\_asset',\n",
    "        'new':'\\\\text{cashflow to asset}'\n",
    "        },\n",
    "        {\n",
    "        'old':'cashflow\\_to\\_tangible',\n",
    "        'new':'\\\\text{cashflow}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_cashflow\\_to\\_tangible',\n",
    "        'new':'\\\\text{cashflow}'\n",
    "        },\n",
    "        {\n",
    "        'old':'d\\_credit\\_constraintBELOW',\n",
    "        'new':'\\\\text{Fin dep}_{i}'\n",
    "        },\n",
    "        ## control\n",
    "        {\n",
    "        'old':'age + 1',\n",
    "        'new':'\\\\text{age}'\n",
    "        },\n",
    "        {\n",
    "        'old':'export\\_to\\_sale',\n",
    "        'new':'\\\\text{export to sale}'\n",
    "        },\n",
    "        {\n",
    "        'old':'labor\\_capital',\n",
    "        'new':'\\\\text{labor to capital}'\n",
    "        },\n",
    "        ### Supply demand external finance\n",
    "        {\n",
    "        'old':'supply\\_all\\_credit',\n",
    "        'new':'\\\\text{all credit}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_credit\\_supply\\_short\\_term',\n",
    "        'new':'\\\\text{Short term loan}_{pt}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_credit\\_supply',\n",
    "        'new':'\\\\text{All loan}_{pt}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_credit\\_supply\\_long\\_term',\n",
    "        'new':'\\\\text{Long-term loan}_{pt}'\n",
    "        },\n",
    "        {\n",
    "        'old':'fin\\_dev',\n",
    "        'new':'\\\\text{financial development}_{pt}'\n",
    "        },\n",
    "        {\n",
    "        'old':'credit\\_constraint',\n",
    "        'new':'\\\\text{credit constraint}'\n",
    "        },\n",
    "        {\n",
    "        'old':'soe\\_vs\\_priPRIVATE',\n",
    "        'new':'\\\\text{private}'\n",
    "        },\n",
    "        ## TFP\n",
    "        {\n",
    "        'old':'tfp\\_cit',\n",
    "        'new':'\\\\text{TFP}'\n",
    "        },\n",
    "        ### year\n",
    "        {\n",
    "        'old':'year1998',\n",
    "        'new':'\\\\text{1998}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year1999',\n",
    "        'new':'\\\\text{1999}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2000',\n",
    "        'new':'\\\\text{2000}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2001',\n",
    "        'new':'\\\\text{2001}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2002',\n",
    "        'new':'\\\\text{2002}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2003',\n",
    "        'new':'\\\\text{2003}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2004',\n",
    "        'new':'\\\\text{2004}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2005',\n",
    "        'new':'\\\\text{2005}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2006',\n",
    "        'new':'\\\\text{2006}'\n",
    "        },\n",
    "        {\n",
    "        'old':'year2007',\n",
    "        'new':'\\\\text{2007}'\n",
    "        },\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    \n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]: \n",
      "---------------------------------------------------------------------------\n",
      "NameError                                 Traceback (most recent call last)\n",
      "script_8394471519434058915 in <module>\n",
      "----> sys.path.append(os.path.join(parent_path, 'utils'))\n",
      "      import latex.latex_beautify as lb\n",
      "      \n",
      "\n",
      "NameError: name 'sys' is not defined\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/r_env/lib/python3.9/site-packages/sos_notebook/kernel.py:1216: RuntimeWarning: coroutine 'ZMQSocketChannel.msg_ready' was never awaited\n",
      "  while self.KC.shell_channel.msg_ready():\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/ubuntu/anaconda3/envs/r_env/lib/python3.9/site-packages/sos_notebook/kernel.py:1217: RuntimeWarning: coroutine 'ZMQSocketChannel.get_msg' was never awaited\n",
      "  self.KC.shell_channel.get_msg()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(\n",
    "    year = relevel(as.factor(year), ref='2001'),\n",
    "    period = relevel(as.factor(period), ref='FALSE'),\n",
    "    polluted_d50i = relevel(as.factor(polluted_d50i), ref='BELOW'),\n",
    "    polluted_d75i = relevel(as.factor(polluted_d75i), ref='BELOW'),\n",
    "    polluted_d80i = relevel(as.factor(polluted_d80i), ref='BELOW'),\n",
    "    polluted_d85i = relevel(as.factor(polluted_d85i), ref='BELOW'),\n",
    "    polluted_d90i = relevel(as.factor(polluted_d90i), ref='BELOW'),\n",
    "    polluted_d95i = relevel(as.factor(polluted_d95i), ref='BELOW'),\n",
    "    polluted_mi = relevel(as.factor(polluted_mi), ref='BELOW'),\n",
    "    d_avg_ij_o_city_mandate = relevel(as.factor(d_avg_ij_o_city_mandate), ref=\"FALSE\"),\n",
    "    fin_dev = 1- share_big_loan,\n",
    "    lag_fin_dev = 1- lag_share_big_loan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "head(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "Aggregate at the province-industry-year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "df_agg <- df_final %>%\n",
    "group_by(province_en, ind2, year, period, fe_p_i , fe_t_i , fe_p_t) %>%\n",
    "summarize(\n",
    "    tso2 = sum(tso2),\n",
    "    tcod = sum(tcod),\n",
    "    twaste_water = sum(twaste_water),\n",
    "    output = sum(output),\n",
    "    employment = sum(employment),\n",
    "    capital = sum(capital),\n",
    "    target_reduction_so2_p = max(target_reduction_so2_p),\n",
    "    target_reduction_co2_p = max(target_reduction_co2_p),\n",
    "    lag_credit_supply = max(lag_credit_supply),\n",
    "    lag_credit_supply_long_term = max(lag_credit_supply_long_term),\n",
    "    fin_dev = max(fin_dev),\n",
    "    lag_fin_dev = max(lag_fin_dev),\n",
    "    credit_constraint = max(credit_constraint),\n",
    ") %>%\n",
    "ungroup()%>%\n",
    "mutate(\n",
    "    year = relevel(as.factor(year), ref='2005'),\n",
    "    year1 = relevel(as.factor(year), ref='1998')\n",
    ")\n",
    "\n",
    "head(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "## Variables Definition\n",
    "\n",
    "1. credit_supply: Province-year supply all loans over GDP\n",
    "2. credit_supply_long_term: Province-year supply long term loans over GDP\n",
    "3. fin_dev: Share of non-4-SOCBs' share in credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 1:Financial development over time\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{$S O 2_{c k t}=\\alpha$ Financial Dependencies $_{k} \\times \\text{credit supply}_{pt} +\\beta X_{c k t}+\\mu_{c t}+\\gamma_{k t}+\\delta_{c k}+\\epsilon_{c k t}$}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{$S O 2_{c k t}=\\alpha$ Financial Dependencies $_{k} \\times \\text{Fin.Dev}_{pt} + +\\beta X_{c k t}+\\mu_{c t}+\\gamma_{k t}+\\delta_{c k}+\\epsilon_{c k t}$}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "1. Table 1: SO2 emission reduction, credit supply and financial development\n",
    "  1. All loan interacted with credit constraint\n",
    "  2. Long term loan with credit constraint\n",
    "  3. Financial development with credit constraint\n",
    "\n",
    "**Message**\n",
    "\n",
    "* An increase of supply of credit or improvement of financial development (deregulation of banking sectors) is beneficial for the reduction of SO2 emission\n",
    "  * Deregulation has a stronger effect on constraint sectors than non-constraint → backed by the theory that credit openness is more beneficial for constraint sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### City level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.tex', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ind2, SUM(tso2) as sum_tso2\n",
    "FROM fin_dep_pollution_baseline_industry \n",
    "WHERE year = '1998'\n",
    "GROUP BY ind2\n",
    "ORDER BY sum_tso2\n",
    "\"\"\"\n",
    "list_polluted = s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename='polluted',  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        )\n",
    "list_polluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "library(fixest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "feols(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            lag_credit_supply : credit_constraint +\n",
    "            lag_deregulation_ct : credit_constraint\n",
    "           | fe_t_i+ fe_c_i+fe_c_t,\n",
    "      df_final%>% filter(tso2 > 500),\n",
    "      ~geocode4_corr+ ind2\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(feols(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            lag_credit_supply : credit_constraint +\n",
    "            lag_deregulation_ct : credit_constraint\n",
    "           | fe_t_i+fe_c_t+fe_c_i  , df_final%>% filter(tso2 > 500)), vcov = \"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "data(trade)\n",
    "gravity_pois = fepois(Euros ~ log(dist_km) | Origin + Destination + Product + Year, trade)\n",
    "summary(gravity_pois, vcov = \"twoway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "t <- feols(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            log(lag_credit_supply) : credit_constraint +\n",
    "            log(lag_concentration_sob_ct) : credit_constraint|\n",
    "           geocode4_corr\n",
    "           , df_final%>% filter(tso2 > 500))\n",
    "summary(t,vcov  = \"iid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            lag_credit_supply * credit_constraint +\n",
    "            lag_concentration_sob_ct * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            #intensity + \n",
    "            log(lag_credit_supply) * credit_constraint \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            log(lag_credit_supply) * financial_dep_us \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "summary(felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            intensity + \n",
    "            log(lag_credit_supply) * financial_dep_us \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "to_remove <- c(\n",
    "    24, 21, 23,#, 42,18,\n",
    "    33, 32, 26#, 31,17\n",
    ")\n",
    "## SO2\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_final%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(\n",
    "               tso2 > 500 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_final%>% filter(tso2 > 500 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "            \n",
    "dep <- \"Dependent variable: Pollution emission\"\n",
    "fe1 <- list(\n",
    "    c(\"City-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "     ),\n",
    "    c(\"Time-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "     ),\n",
    "    c(\"City-Time\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "     )\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"Pollution emission, credit supply and financial development\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(1). \" \\\n",
    "\"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit) \" \\\n",
    "\"Columns 4 to 6 exclude the top and bottom 3 most polluted sectors in 1998 \" \\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\" \\\n",
    "\"Heteroskedasticity-robust standard errors \" \\\n",
    "\"clustered at the city-industry level appear in parentheses.\"\n",
    "\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 2: heterogeneous effect: SOE vs Private\n",
    "\n",
    "City ownership are available for the following variables:\n",
    "\n",
    "- output\n",
    "- capital\n",
    "- employment\n",
    "- sales\n",
    "\n",
    "**How is it constructed**\n",
    "\n",
    "- city ownership public vs private\n",
    "    - Aggregate output by ownership and city\n",
    "    - A given city will have SOE asset tangibility and PRIVATE asset tangibility [output, employment, capital and sales]\n",
    "    - If asset tangibility SOE above Private then city is dominated by SOE\n",
    "\n",
    "Notebook reference: \n",
    "\n",
    "https://github.com/thomaspernet/Financial_dependency_pollution/blob/master/02_data_analysis/01_model_estimation/00_estimate_fin_ratio/03_so2_fin_ratio_sector.md#table-3-heterogeneity-effect-city-ownership-public-vs-private-domestic-vs-foreign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH test AS (\n",
    "  SELECT \n",
    "    *,\n",
    "    CASE WHEN LENGTH(cic) = 4 THEN substr(cic, 1, 2) ELSE concat(\n",
    "      '0', \n",
    "      substr(cic, 1, 1)\n",
    "    ) END AS indu_2,\n",
    "    CASE WHEN ownership = 'SOE' THEN 'SOE' ELSE 'PRIVATE' END AS soe_vs_pri,\n",
    "    CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS for_vs_dom \n",
    "  FROM \n",
    "    firms_survey.asif_firms_prepared \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON asif_firms_prepared.citycode = no_dup_citycode.extra_code\n",
    "  \n",
    ") \n",
    "SELECT year, soe, geocode4_corr, indu_2,SUM(output) as output, SUM(employ) as employ, SUM(captal) as capital\n",
    "FROM (\n",
    "SELECT *,\n",
    "CASE WHEN ownership in ('SOE') THEN 'SOE' ELSE 'PRIVATE' END AS soe\n",
    "FROM test \n",
    "  )\n",
    "  GROUP BY soe, geocode4_corr, year, indu_2\n",
    "\"\"\"\n",
    "df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=\"test\",  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "for v in ['output','employ', 'capital']:\n",
    "    for t in [.5, .4, .3, .2, .1]:\n",
    "        df_ = (\n",
    "            df\n",
    "            .set_index(['year','indu_2', 'soe', 'geocode4_corr'])\n",
    "            .unstack(-2)\n",
    "            .assign(\n",
    "                soe_dominated = lambda x: x[(v, 'SOE')] > x[(v, 'PRIVATE')],\n",
    "                share_soe = lambda x: x[(v, 'SOE')] / (x[(v, 'SOE')] + x[(v, 'PRIVATE')])\n",
    "            )\n",
    "            #.loc[lambda x: x['soe_dominated'].isin([True])]\n",
    "            .collapse_levels(\"_\")\n",
    "            .reset_index()\n",
    "            [['year','geocode4_corr', 'indu_2', \"soe_dominated\", \n",
    "             'share_soe'\n",
    "             ]]\n",
    "            .loc[lambda x: x['year'].isin([\"2002\"])]\n",
    "            .drop(columns = ['year'])\n",
    "            .rename(columns = {'indu_2':'ind2'})\n",
    "            .loc[lambda x: x['share_soe']> t]\n",
    "            #.groupby(['soe_dominated'])\n",
    "            #.agg({'share_soe':'describe'})\n",
    "            .to_csv('list_city_soe_{}_{}.csv'.format(v, t))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH test AS (\n",
    "  SELECT \n",
    "    *,\n",
    "    CASE WHEN LENGTH(cic) = 4 THEN substr(cic, 1, 2) ELSE concat(\n",
    "      '0', \n",
    "      substr(cic, 1, 1)\n",
    "    ) END AS indu_2,\n",
    "    CASE WHEN ownership = 'SOE' THEN 'SOE' ELSE 'PRIVATE' END AS soe_vs_pri,\n",
    "    CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS for_vs_dom \n",
    "  FROM \n",
    "    firms_survey.asif_firms_prepared \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        extra_code, \n",
    "        geocode4_corr \n",
    "      FROM \n",
    "        chinese_lookup.china_city_code_normalised \n",
    "      GROUP BY \n",
    "        extra_code, \n",
    "        geocode4_corr\n",
    "    ) as no_dup_citycode ON asif_firms_prepared.citycode = no_dup_citycode.extra_code\n",
    "  \n",
    ") \n",
    "SELECT year, foreign, geocode4_corr, indu_2,SUM(output) as output, SUM(employ) as employ, SUM(captal) as capital\n",
    "FROM (\n",
    "SELECT *,\n",
    "CASE WHEN ownership in ('HTM', 'FOREIGN') THEN 'FOREIGN' ELSE 'DOMESTIC' END AS foreign\n",
    "FROM test \n",
    "  )\n",
    "  GROUP BY foreign, geocode4_corr, year, indu_2\n",
    "\n",
    "\"\"\"\n",
    "df = (s3.run_query(\n",
    "        query=query,\n",
    "        database=db,\n",
    "        s3_output='SQL_OUTPUT_ATHENA',\n",
    "        filename=\"test\",  # Add filename to print dataframe\n",
    "        destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        dtype = dtypes\n",
    "    )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "for v in ['output','employ', 'capital']:\n",
    "    for t in [.5, .4, .3, .2, .1]:\n",
    "        (\n",
    "            df\n",
    "            .set_index(['year','indu_2', 'foreign', 'geocode4_corr'])\n",
    "            .unstack(-2)\n",
    "            .assign(\n",
    "                for_dominated = lambda x: x[(v, 'FOREIGN')] > x[(v, 'DOMESTIC')],\n",
    "                share_for = lambda x: x[(v, 'FOREIGN')] / (x[(v, 'FOREIGN')] + x[(v, 'DOMESTIC')])\n",
    "            )\n",
    "            .collapse_levels(\"_\")\n",
    "            .reset_index()\n",
    "            [['year','geocode4_corr', 'indu_2', \"for_dominated\", \n",
    "             'share_for'\n",
    "             ]]\n",
    "            .loc[lambda x: x['year'].isin([\"2002\"])]\n",
    "            .drop(columns = ['year'])\n",
    "            .rename(columns = {'indu_2':'ind2'})\n",
    "            .loc[lambda x: x['share_for']> t]\n",
    "            #.groupby(['soe_dominated'])\n",
    "            #.agg({'share_soe':'describe'})\n",
    "            .to_csv('list_city_for_{}_{}.csv'.format(v, t))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_1'\n",
    "table_nb = 2\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "df_soe <- df_final %>% inner_join(read_csv('list_city_soe_employ_0.3.csv'))\n",
    "df_priv <- df_final %>% left_join(read_csv('list_city_soe_employ_0.3.csv')) %>% filter(is.na(share_soe))\n",
    "print(dim(df_soe)[1] + dim(df_priv)[1] == dim(df_final)[1])\n",
    "### CITY DOMINATED\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_soe%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_priv%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_soe%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_priv%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_soe%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_priv%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "dep <- \"Dependent variable: Pollution emission\"\n",
    "fe1 <- list(\n",
    "    c(\"City-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"Time-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"City-Time\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"Pollution emission, credit supply and financial development, City dominated public/private\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit. \" \\\n",
    "\"Cities split are based on the presence of SOEs firms. 'Above' means the total output produced by \"\\\n",
    "\"SOEs firms exceed the output of private firms. \" \\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\" \\\n",
    "\"Heteroskedasticity-robust standard errors \" \\\n",
    "\"clustered at the city-industry level appear in parentheses.\"\\\n",
    " \n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Above', 'Below','Above', 'Below', 'Above', 'Below' ]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 3: heterogeneous effect: Domestic vs Foreign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_1'\n",
    "table_nb = 3\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "df_for <- df_final %>% inner_join(read_csv('list_city_for_employ_0.3.csv'))\n",
    "df_dom <- df_final %>% left_join(read_csv('list_city_for_employ_0.3.csv')) %>% filter(is.na(share_for))\n",
    "print(dim(df_for)[1] + dim(df_dom)[1] == dim(df_final)[1])\n",
    "### CITY DOMINATED\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_for%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_dom%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_for%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_dom%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_for%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_dom%>% filter(tso2 > 500),\n",
    "            exactDOF = TRUE)\n",
    "dep <- \"Dependent variable: SO2 emission\"\n",
    "fe1 <- list(\n",
    "    c(\"City-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"Time-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"City-Time\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"SO2 emission reduction, credit supply and financial development, City dominated Domestic/Foreign\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit. \" \\\n",
    "\"Cities split are based on the presence of foreign's firms. 'Above' means the total output produced by \"\\\n",
    "\"foreign's firms exceed the output of domestic firms. \" \\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\" \\\n",
    "\"Heteroskedasticity-robust standard errors \" \\\n",
    "\"clustered at the city-industry level appear in parentheses.\"\\\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& Above', 'Below','Above', 'Below', 'Above', 'Below' ]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 5: TCZ & SPZ policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 4\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500 & tcz == 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply) * credit_constraint \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500 & tcz == 1),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint\n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500 & tcz == 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(lag_credit_supply_long_term) * credit_constraint \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr + ind2, df_final%>% filter(tso2 > 500 & tcz == 1),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_final%>% filter(tso2 > 500 & tcz == 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(tso2) ~  \n",
    "            log(output) + log(employment) + log(capital) + \n",
    "            log(fin_dev) * credit_constraint \n",
    "           |  fe_c_i + fe_t_i + fe_c_t|0 | geocode4_corr+ ind2, df_final%>% filter(tso2 > 500 & tcz == 1),\n",
    "            exactDOF = TRUE)\n",
    "dep <- \"Dependent variable: SO2 emission\"\n",
    "fe1 <- list(\n",
    "    c(\"City-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"Time-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"City-Time\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"SO2 emission reduction, credit supply and financial development\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit. \" \\\n",
    "\"The list of TCZ cities is provided by the State Council, 1998 \" \\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the city-industry level appear in parentheses.\"\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = ['& No TCZ', 'TCZ','No TCZ', 'TCZ', 'No TCZ', 'TCZ' ]\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 6: Environmental policy and financial development\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{$S O 2_{p k t}=\\alpha$ Financial Dependencies $_{k} \\times \\text{credit supply}_{pt} \\times \\text{policy mandate}_p +\\mu_{p t}+\\gamma_{k t}+\\delta_{p k}+\\epsilon_{p k t}$}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Environmental policy and financial development:  Aggregate at the province-industry-year level\n",
    "1. Evaluate the effect of credit constraint in provinces with stringent environmental policy\n",
    "  1. SO2\n",
    "    1. credit_constraint * target_reduction_so2_p * period\n",
    "    2. lag_credit_supply*credit_constraint * target_reduction_so2_p * period\n",
    "  2. ~COD~\n",
    "      1. ~credit_constraint * target_reduction_co2_p * period~\n",
    "      2. ~lag_credit_supply*credit_constraint * target_reduction_co2_p * period~\n",
    "\n",
    "Message \n",
    "* Capital within financially constrained industries have been relocated toward investment less harming for the environment (i.e. lower emission) in province with stringent environmental policy\n",
    "* One channel is the increase of the credit access → more loan availability in constraint industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 5\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Province level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "            credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_1 <- felm(log(tso2) ~  \n",
    "            log(lag_credit_supply)*credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_2 <- felm(log(tso2) ~  \n",
    "            log(lag_credit_supply_long_term)*credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_3 <- felm(log(tso2) ~  \n",
    "            credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_4 <- felm(log(tso2) ~  \n",
    "            log(lag_credit_supply)*credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "t_5 <- felm(log(tso2) ~  \n",
    "            log(lag_credit_supply_long_term)*credit_constraint * target_reduction_so2_p * period\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0 & !(ind2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "dep <- \"Dependent variable: SO2 emission\"\n",
    "fe1 <- list(\n",
    "    c(\"Province-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"Time-industry\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"),\n",
    "    c(\"Province-Time\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2#, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"SO2 emission reduction, credit constraint and policy mandate\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(2). \" \\\n",
    "\" SO2 city mandate measures the total amount of SO2 a city needs to reduce by the end of the 11th FYP. \" \\\n",
    "\"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit. \" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the product level appear inparentheses.\"\\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Eligible': 2,\n",
    "#    'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "#new_r = ['& test1', 'test2']\n",
    "\n",
    "reorder = {\n",
    "    6:0,\n",
    "    3:5\n",
    "    #0:2,\n",
    "    #1:3\n",
    "    #9:2,\n",
    "    #0:3,\n",
    "    #6:5\n",
    "    #14:5\n",
    "}\n",
    "\n",
    "lb.beautify(table_number = table_nb,\n",
    "            reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 200,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 7: parallel trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 6\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t_0 <- felm(log(tso2) ~  \n",
    "           credit_constraint * target_reduction_so2_p * year\n",
    "           |  fe_p_i + fe_t_i + fe_p_t|0 | province_en +ind2, df_agg%>% \n",
    "             filter( target_reduction_so2_p > 0),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "\n",
    "dep <- \"Dependent variable: SO2 emission\"\n",
    "fe1 <- list(\n",
    "    c(\"Province-industry\", \"Yes\"),\n",
    "    c(\"Province-industry\", \"Yes\"),\n",
    "    c(\"Province-Time\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0\n",
    "),\n",
    "    title=\"parallel trend\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"The year 2005 is the omitted category. \"\\\n",
    "\" SO2 city mandate measures the total amount of SO2 a city needs to reduce by the end of the 11th FYP. \" \\\n",
    "\"All loan is the share of total loan normalised by the GDP. \" \\\n",
    "\"Long-term loan is the share of long term loan normalised by the GDP. \" \\\n",
    "\"Financial development is defined as the share of non-4-SOCBs' share in credit. \" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the product level appear inparentheses.\"\\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            #multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            #multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder,\n",
    "            parallel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc\n",
    "import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_pollution_credit_constraint.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)\n",
    "notebookname = \"00_credit_supply.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "create_report.create_report(extension = \"html\", keep_code = False, notebookname =  notebookname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path,\n",
    "          str(Path(path).parent),\n",
    "          #os.path.join(str(Path(path).parent), \"00_download_data_from\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"00_statistical_exploration\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"01_model_estimation\"),\n",
    "         ]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', name_json)\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.26.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
